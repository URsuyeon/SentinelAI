# src/rag_agent/retriever.py
from fastapi import FastAPI
from pydantic import BaseModel
from typing import Dict, Any, List
import logging
import os
import asyncio

# LangChain
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
from langchain_qdrant import QdrantVectorStore
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import DirectoryLoader, TextLoader

# Qdrant client
from qdrant_client import QdrantClient

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | RAG | %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI(title="Simple RAG Agent API", version="0.1")

DISABLE_RAG_INTEGRATION = os.getenv("DISABLE_RAG_INTEGRATION", "True").lower() in ('true', '1', 't')
logger.info(f"âš™ï¸ RAG Integration Status: {'MOCKING' if DISABLE_RAG_INTEGRATION else 'ACTIVE'}")

# ì„ë² ë”© ëª¨ë¸ (ì‘ê³  ë¹ ë¦„)
embeddings = FastEmbedEmbeddings(model_name="BAAI/bge-small-en-v1.5")

vector_db = None

def init_vector_db():
    global vector_db
    if DISABLE_RAG_INTEGRATION or vector_db:
        return

    logger.info("ğŸ› ï¸ Initializing Vector DB (minimal mode)...")

    client = QdrantClient(url="http://qdrant:6333")
    
    # í•­ìƒ ê¹¨ë—í•œ ìƒíƒœë¡œ ì‹œì‘
    try:
        client.delete_collection(collection_name="k8s_incident_knowledge")
        logger.info("Old collection deleted")
    except Exception:
        pass

    # ë¬¸ì„œ ë¡œë“œ
    loader = DirectoryLoader("/app/docs/kubernetes", glob="**/*.md", loader_cls=TextLoader)
    documents = loader.load()
    logger.info(f"ğŸ“š Loaded {len(documents)} documents")

    # ë¹ˆ ë¬¸ì„œ ì œê±°ë§Œ í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë‹¤ ì‚¬ìš©
    documents = [doc for doc in documents if doc.page_content.strip()]
    logger.info(f"ğŸ“„ After removing empty docs: {len(documents)}")

    if not documents:
        logger.warning("âš ï¸ No documents found")
        return

    # chunk í¬ê¸° ì‘ê²Œ â†’ ë¬¸ì„œê°€ ì§§ì•„ë„ ì—¬ëŸ¬ chunk ìƒì„± ë°©ì§€ + ìµœëŒ€í•œ ì‚½ì…
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=400,
        chunk_overlap=50,
        keep_separator=True
    )
    splits = text_splitter.split_documents(documents)
    logger.info(f"âœ‚ï¸ Split into {len(splits)} chunks")

    if not splits:
        logger.error("âŒ No chunks after splitting")
        return

    # ë°”ë¡œ from_documentsë¡œ ì‚½ì… (ì¤‘ê°„ í•„í„°ë§ ì—†ìŒ)
    try:
        vector_db = QdrantVectorStore.from_documents(
            documents=splits,
            embedding=embeddings,
            url="http://qdrant:6333",
            collection_name="k8s_incident_knowledge",
            prefer_grpc= False,
        )
        logger.info("ğŸ‰ Vector DB initialized successfully!")
    except Exception as e:
        logger.error(f"âŒ Failed to initialize vector store: {e}")
        vector_db = None

# ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”
init_vector_db()

# --- API ëª¨ë¸ ---
class RAGSearchRequest(BaseModel):
    task_id: str
    detection_log: Dict[str, Any]
    execution_log: List[Dict[str, Any]]

class RAGResult(BaseModel):
    title: str
    content: str

class RAGSearchResponse(BaseModel):
    rag_results: List[RAGResult]

def _search_vector_db(req: RAGSearchRequest) -> List[RAGResult]:
    if not vector_db:
        logger.warning("Vector DB not ready â†’ fallback to mock")
        return _mock_search_knowledge_base(req)

    query = f"""
{req.detection_log.get('event_type', '')}
{req.detection_log.get('pod_name', '')} {req.detection_log.get('namespace', 'default')}
{req.detection_log.get('raw_log_tail', '')}
{' '.join(req.detection_log.get('events', []))}
""".strip()

    retriever = vector_db.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 3}  # ê²°ê³¼ ìˆ˜ ì¤„ì„
    )
    docs = retriever.invoke(query)

    results = []
    for doc in docs:
        title = doc.metadata.get("source", "Unknown").split("/")[-1].replace(".md", "")
        results.append(RAGResult(title=title, content=doc.page_content.strip()))

    if not results:
        results.append(RAGResult(title="No results", content="ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."))

    return results

def _mock_search_knowledge_base(req: RAGSearchRequest) -> List[RAGResult]:
    logger.info(f"ğŸ” [MOCK SEARCH] Task {req.task_id}")
    
    full_text = (
        f"{req.detection_log.get('event_type', '')} "
        f"{req.detection_log.get('describe_snippet', '')} "
        f"{req.detection_log.get('raw_log_tail', '')} "
        + " ".join([log.get("output", "") for log in req.execution_log])
    ).lower()

    results = []

    if "crashloopbackoff" in full_text:
        results.append(RAGResult(
            title="CrashLoopBackOff Troubleshooting",
            content="CrashLoopBackOffëŠ” ì»¨í…Œì´ë„ˆê°€ ë°˜ë³µ ì¢…ë£Œë˜ëŠ” ìƒíƒœì…ë‹ˆë‹¤. kubectl describe podë¡œ ì¢…ë£Œ ì½”ë“œì™€ ì´ìœ ë¥¼ í™•ì¸í•˜ê³ , í•„ìš”ì‹œ kubectl logs --previousë¡œ ì´ì „ ë¡œê·¸ë¥¼ ë³´ì„¸ìš”."
        ))
    elif "oomkilled" in full_text or "out of memory" in full_text:
        results.append(RAGResult(
            title="OOMKilled",
            content="ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. Podì˜ resources.limits.memoryë¥¼ ëŠ˜ë¦¬ê³  ë¡¤ë§ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”."
        ))
    elif "pending" in full_text:
        results.append(RAGResult(
            title="Pending Pod",
            content="Podê°€ Pendingì´ë©´ ë¦¬ì†ŒìŠ¤ ë¶€ì¡±, taint, PVC ë¬¸ì œ ë“±ì„ ì˜ì‹¬í•˜ì„¸ìš”. kubectl describe podì˜ Eventsë¥¼ í™•ì¸í•˜ì„¸ìš”."
        ))

    if not results:
        results.append(RAGResult(
            title="General Advice",
            content="kubectl describe podì™€ kubectl logsë¥¼ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”."
        ))

    return results

def _get_rag_results(req: RAGSearchRequest) -> List[RAGResult]:
    return _mock_search_knowledge_base(req) if DISABLE_RAG_INTEGRATION else _search_vector_db(req)

@app.post('/search', response_model=RAGSearchResponse)
async def search_knowledge(req: RAGSearchRequest):
    logger.info(f"ğŸ“© [POST /search] Task {req.task_id}")
    await asyncio.sleep(0.5)  # ì•½ê°„ì˜ ì§€ì—° (ì‹¤ì œ ê²€ìƒ‰ ëŠë‚Œ)
    return RAGSearchResponse(rag_results=_get_rag_results(req))

@app.get('/health')
async def health():
    return {"status": "ok", "rag_active": not DISABLE_RAG_INTEGRATION, "vector_db_ready": vector_db is not None}

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8036, log_level="info")