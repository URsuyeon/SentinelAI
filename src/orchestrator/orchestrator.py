# src/orchestrator/orchestrator.py
from fastapi import Header, FastAPI, HTTPException, BackgroundTasks, Request
from fastapi.encoders import jsonable_encoder
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timedelta
import secrets
import logging
import os
import httpx
import json
import yaml
from kubernetes import config
# AuthManager ì„í¬íŠ¸
from src.auth.auth import auth_manager
import asyncio

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | ORCHESTRATOR | %(message)s')
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
BOSS_TOKEN = os.getenv("BOSS_TOKEN", "dev-token")
ANALYZER_URL = os.getenv("ANALYZER_URL", "http://127.0.0.1:8034")
EXECUTOR_URL = os.getenv("EXECUTOR_URL", "http://127.0.0.1:8035")
RAG_URL = os.getenv("RAG_URL", "http://127.0.0.1:8036")
NOTIFIER_URL = os.getenv("NOTIFIER_URL", "http://127.0.0.1:8037")
ORCHESTRATOR_CALLBACK_URL = os.getenv("ORCHESTRATOR_CALLBACK_URL", "http://127.0.0.1:8032")
K8S_KUBECONFIG_PATH = os.getenv("K8S_KUBECONFIG_PATH", "/app/kubeconfig")
app = FastAPI(title="Orchestrator API", version="0.1")

# Task ìƒíƒœ ì €ì¥ì†Œ
TASK_STORE: Dict[str, Dict[str, Any]] = {}

# í¬ë“œë³„ ì´ë²¤íŠ¸ ë²„í¼ (namespace/pod_nameì„ í‚¤ë¡œ ì‚¬ìš©)
POD_BUFFERS: Dict[str, Dict[str, Any]] = {}  # pod_key -> {"events": List[Dict], "timer": Optional[asyncio.TimerHandle], "start_time": datetime}

# --- ë°ì´í„° ëª¨ë¸ ---
class DetectRequest(BaseModel):
    timestamp: datetime = Field(..., description="ISO8601 UTC timestamp")
    namespace: str
    pod_name: str              
    event_type: str
    
    phase: Optional[str] = None
    container_statuses: Optional[List[Dict[str, Any]]] = None
    reasons: Optional[List[str]] = None
    
    raw_log_tail: Optional[str] = ""
    describe_snippet: Optional[str] = "" 
    
    metadata: Optional[Dict[str, Any]] = None
    detection_signature: Optional[str] = None

    class Config:
        extra = 'allow'

class DetectResponse(BaseModel):
    status: str
    task_id: str

class AnalyzeCommandResponse(BaseModel):
    command_type: str # 'read' or 'write'
    command_list: List[str]
    is_risky: bool = False # ìµœì¢… í•´ê²° ëª…ë ¹ ì‹œì—ë§Œ ì‚¬ìš©

class ExecutorCallback(BaseModel):
    task_id: str
    status: str # 'success' or 'failure'
    execution_logs: List[Dict[str, Any]]

class SlackCallback(BaseModel):
    task_id: str
    approved: bool
    reason: Optional[str] = None

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---

def _generate_task_id() -> str:
    t = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')
    suf = secrets.token_hex(3)
    return f"task-{t}-{suf}"

async def _http_post(url: str, data: Dict[str, Any], task_id: str, step: str):
    """HTTP POST ìš”ì²­ì„ ë³´ë‚´ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"""
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            payload = jsonable_encoder(data)
            resp = await client.post(url, json=payload)
            if resp.status_code == 200:
                logger.info(f"â¡ï¸ [{step}] Task {task_id} forwarded to {url}. Response: {resp.json()}")
                return resp.json()
            else:
                logger.error(f"âŒ [{step}] Task {task_id} failed to forward to {url}. Status: {resp.status_code}, Body: {resp.text[:200]}")
                TASK_STORE[task_id]["status"] = f"failed_at_{step}"
                return None
    except Exception as e:
        logger.error(f"âŒ [{step}] Task {task_id} failed to forward to {url}. Exception: {e}")
        TASK_STORE[task_id]["status"] = f"failed_at_{step}"
        return None

def load_cluster_info(kubeconfig_path: str) -> Tuple[str, str]:
    """
    kubeconfig íŒŒì¼ì—ì„œ
    - API Server ì£¼ì†Œ
    - CA ì¸ì¦ì„œ ë°ì´í„°
    ë¥¼ ì¶”ì¶œ
    """
    with open(kubeconfig_path, "r") as f:
        kubeconfig = yaml.safe_load(f)

    cluster = kubeconfig["clusters"][0]["cluster"]

    api_server = cluster["server"]
    ca_data = cluster.get("certificate-authority-data")

    if not api_server or not ca_data:
        raise ValueError("Invalid kubeconfig: missing server or CA data")

    return api_server, ca_data

def build_kubeconfig(api_server: str, ca_crt: str, token: str) -> str:
    return f"""
apiVersion: v1
kind: Config

clusters:
- name: sentinel-cluster
  cluster:
    server: {api_server}
    certificate-authority-data: {ca_crt}

users:
- name: sentinel-executor
  user:
    token: {token}

contexts:
- name: sentinel-context
  context:
    cluster: sentinel-cluster
    user: sentinel-executor

current-context: sentinel-context
""".strip()

def combine_events(events: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ì—¬ëŸ¬ DetectRequest ì´ë²¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ í˜ì´ë¡œë“œë¡œ í•©ì¹¨.
    """
    if not events:
        return {}

    first_event = events[0]
    combined = first_event.copy()

    combined["timestamp"] = max(e["timestamp"] for e in events)
    combined["event_types"] = list(set(e["event_type"] for e in events))  # ì¤‘ë³µ ì œê±°

    all_reasons = set()
    for e in events:
        all_reasons.update(e.get("reasons", []))
    combined["reasons"] = list(all_reasons)

    combined["container_statuses"] = [
        status for e in events 
        for status in (e.get("container_statuses") or [])
    ]
    
    combined["raw_log_tail"] = "\n".join(e.get("raw_log_tail", "") for e in events if e.get("raw_log_tail"))
    combined["describe_snippet"] = "\n".join(e.get("describe_snippet", "") for e in events if e.get("describe_snippet"))
    combined["detection_signatures"] = list(set(e.get("detection_signature", "") for e in events if e.get("detection_signature")))
    combined["metadata"] = first_event.get("metadata", {})
    combined["original_events"] = events

    return combined

# --- í•µì‹¬ ì›Œí¬í”Œë¡œìš° í•¨ìˆ˜ ---

async def _start_workflow(task_id: str, payload: Dict[str, Any]):
    """
    ì›Œí¬í”Œë¡œìš°ì˜ ì‹œì‘ì : Detector ì•Œë¦¼ ìˆ˜ì‹  í›„ ì´ˆê¸° ë¶„ì„ ìš”ì²­
    """
    TASK_STORE[task_id] = {
        "received_at": datetime.utcnow().isoformat() + 'Z',
        "payload": payload,
        "status": "queued",
        "history": []
    }
    pod = payload.get('pod_name', 'unknown')
    evt = payload.get('event_type', 'unknown')
    logger.info(f"âœ… [WORKFLOW START] TaskID: {task_id}")
    logger.info(f"   â””â”€â”€ Event: {pod} [{evt}] | Signature: {payload.get('detection_signature')}")

    TASK_STORE[task_id]["status"] = "analyzing_initial"
    TASK_STORE[task_id]["history"].append({"step": "analyzing_initial", "timestamp": datetime.utcnow().isoformat() + 'Z'})

    # 1. Analyzer Agentì— ì´ˆê¸° ë¶„ì„ ìš”ì²­ (ì¦ê±° ìˆ˜ì§‘ ëª…ë ¹ì–´ ìš”ì²­)
    analyze_req = {"task_id": task_id, "detect_request": payload}
    analyze_resp = await _http_post(f"{ANALYZER_URL}/analyze/initial", analyze_req, task_id, "ANALYZER_INITIAL")
    
    if not analyze_resp:
        return

    try:
        analyze_cmd = AnalyzeCommandResponse(**analyze_resp)
        TASK_STORE[task_id]["initial_commands"] = analyze_cmd.dict()
        
        # 2. í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê²€ì¦ (ì½ê¸° ì „ìš©)
        for cmd in analyze_cmd.command_list:
            if not auth_manager.check_whitelist(cmd, analyze_cmd.command_type):
                logger.error(f"âŒ [WHITELIST] Command rejected: {cmd}")
                TASK_STORE[task_id]["status"] = "failed_whitelist_check"
                await finalize_task(task_id, "failed_final_whitelist_check", "ìµœì¢… ëª…ë ¹ì–´ê°€ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ì— ìœ„ë°˜ë˜ì–´ ì°¨ë‹¨ë¨.")
                return
        
        # 3. ì½ê¸° ì „ìš© í† í° ë°œê¸‰
        read_token = auth_manager.get_execution_token(task_id, analyze_cmd.command_type)
        api_server, ca_data = load_cluster_info(K8S_KUBECONFIG_PATH)

        kubeconfig = build_kubeconfig(
            api_server=api_server,
            ca_crt=ca_data,
            token=read_token
        )

        # 4. Executor Agentì— ì‹¤í–‰ ìš”ì²­
        executor_req = {
            "task_id": task_id,
            "token": read_token,
            "kubeconfig": kubeconfig, 
            "command_type": analyze_cmd.command_type,
            "command_list": analyze_cmd.command_list,
            "callback_url": f"{ORCHESTRATOR_CALLBACK_URL}/executor/callback"
        }
                
        TASK_STORE[task_id]["status"] = "executing_read_commands"
        TASK_STORE[task_id]["history"].append({"step": "executing_read_commands", "timestamp": datetime.utcnow().isoformat() + 'Z'})
        
        await _http_post(f"{EXECUTOR_URL}/execute", executor_req, task_id, "EXECUTOR_READ")
    
    except Exception as e:
        logger.error(f"âŒ [WORKFLOW] Error in initial analysis/execution: {e}")
        await finalize_task(task_id, "failed_initial_execution", "ì´ˆê¸° ë¶„ì„ ë˜ëŠ” ì½ê¸° ëª…ë ¹ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ.")
        
    except Exception as e:
        logger.error(f"âŒ [WORKFLOW] Error in initial analysis/execution: {e}")
        TASK_STORE[task_id]["status"] = "failed_initial_execution"


async def _continue_workflow_after_read(task_id: str, executor_callback: ExecutorCallback):
    """
    Executor Agentë¡œë¶€í„° ì½ê¸° ëª…ë ¹ì–´ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì€ í›„ ì›Œí¬í”Œë¡œìš° ê³„ì†
    """
    logger.info(f"âœ… [EXECUTOR CALLBACK] Task {task_id} received read logs. Status: {executor_callback.status}")
    
    if executor_callback.status != "success":
        await finalize_task(task_id, "failed_read_execution", "ì¦ê±° ìˆ˜ì§‘ ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨.")
        return

    TASK_STORE[task_id]["read_logs"] = executor_callback.execution_logs
    TASK_STORE[task_id]["status"] = "searching_rag"
    TASK_STORE[task_id]["history"].append({"step": "searching_rag", "timestamp": datetime.utcnow().isoformat() + 'Z'})
    
    # 1. RAG Agentì— ë¬¸ì„œ ê²€ìƒ‰ ìš”ì²­
    rag_req = {
        "task_id": task_id,
        "detection_log": TASK_STORE[task_id]["payload"],
        "execution_log": executor_callback.execution_logs
    }
    rag_resp = await _http_post(f"{RAG_URL}/search", rag_req, task_id, "RAG_SEARCH")
    
    if not rag_resp:
        return

    TASK_STORE[task_id]["rag_results"] = rag_resp.get("rag_results", [])
    TASK_STORE[task_id]["status"] = "analyzing_final"
    TASK_STORE[task_id]["history"].append({"step": "analyzing_final", "timestamp": datetime.utcnow().isoformat() + 'Z'})

    # 2. Analyzer Agentì— ìµœì¢… í•´ê²° ëª…ë ¹ì–´ ìš”ì²­
    final_analyze_req = {
        "task_id": task_id,
        "detect_request": TASK_STORE[task_id]["payload"],
        "execution_logs": TASK_STORE[task_id]["read_logs"],
        "rag_results": TASK_STORE[task_id]["rag_results"]
    }
    final_analyze_resp = await _http_post(f"{ANALYZER_URL}/analyze/final", final_analyze_req, task_id, "ANALYZER_FINAL")

    if not final_analyze_resp:
        return

    try:
        final_analyze_cmd = AnalyzeCommandResponse(**final_analyze_resp)
        TASK_STORE[task_id]["final_commands"] = final_analyze_cmd.dict()
        
        # 3. í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê²€ì¦
        for cmd in final_analyze_cmd.command_list:
            if not auth_manager.check_whitelist(cmd, final_analyze_cmd.command_type):
                logger.error(f"âŒ [WHITELIST] Final command rejected: {cmd}")
                await finalize_task(task_id, "failed_final_whitelist_check", "ìµœì¢… ëª…ë ¹ì–´ê°€ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ì— ìœ„ë°˜ë˜ì–´ ì°¨ë‹¨ë¨.")
                return

        # 4. ìœ„í—˜ë„ í™•ì¸
        if final_analyze_cmd.is_risky:
            TASK_STORE[task_id]["status"] = "awaiting_approval"
            TASK_STORE[task_id]["history"].append({"step": "awaiting_approval", "timestamp": datetime.utcnow().isoformat() + 'Z'})
            approval_req = {
                "task_id": task_id,
                "command_list": final_analyze_cmd.command_list,
                "callback_url": f"{ORCHESTRATOR_CALLBACK_URL}/slack/callback"
            }
            post_result = await _http_post(f"{NOTIFIER_URL}/notify/approval", approval_req, task_id, "NOTIFIER_APPROVAL")
            if not post_result:
                logger.warning(f"âš ï¸ Notifier ì‹¤íŒ¨: {task_id} ìë™ ìŠ¹ì¸ ì²˜ë¦¬ (í†µì‹  ì˜¤ë¥˜).")
                TASK_STORE[task_id]["status"] = "auto_approved_due_to_notifier_fail"
                await _execute_final_command(task_id, final_analyze_cmd)
                await finalize_task(task_id, "auto_approved", "Notifier í†µì‹  ì‹¤íŒ¨ë¡œ ìë™ ìŠ¹ì¸ë¨.")
                return
            loop = asyncio.get_running_loop()
            TASK_STORE[task_id]["approval_timer"] = loop.call_later(
                30,  
                lambda: asyncio.create_task(_auto_approve_if_pending(task_id))
            )
        else:
            await _execute_final_command(task_id, final_analyze_cmd)

    except Exception as e:
        logger.error(f"âŒ [WORKFLOW] Error in final analysis/execution: {e}")
        await finalize_task(task_id, "failed_final_execution_prep", "ìµœì¢… ë¶„ì„ ë˜ëŠ” ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ.")


async def _execute_final_command(task_id: str, final_analyze_cmd: AnalyzeCommandResponse):
    """
    ìµœì¢… í•´ê²° ëª…ë ¹ì„ Executor Agentì— ì‹¤í–‰ ìš”ì²­
    """
    # 1. ì“°ê¸° ì „ìš© í† í° ë°œê¸‰
    write_token = auth_manager.get_execution_token(task_id, final_analyze_cmd.command_type)

    api_server, ca_data = load_cluster_info(K8S_KUBECONFIG_PATH)

    kubeconfig = build_kubeconfig(
        api_server=api_server,
        ca_crt=ca_data,
        token=write_token
    )
    
    # 2. Executor Agentì— ì‹¤í–‰ ìš”ì²­
    executor_req = {
        "task_id": task_id,
        "token": write_token,
        "kubeconfig": kubeconfig, 
        "command_list": final_analyze_cmd.command_list,
        "command_type": final_analyze_cmd.command_type,
        "callback_url": f"{ORCHESTRATOR_CALLBACK_URL}/executor/callback"
    }
    
    TASK_STORE[task_id]["status"] = "executing_write_commands"
    TASK_STORE[task_id]["history"].append({"step": "executing_write_commands", "timestamp": datetime.utcnow().isoformat() + 'Z'})
    
    await _http_post(f"{EXECUTOR_URL}/execute", executor_req, task_id, "EXECUTOR_WRITE")


async def _complete_workflow(task_id: str, final_callback: ExecutorCallback):
    logger.info(f"âœ… [EXECUTOR CALLBACK] Task {task_id} received final logs. Status: {final_callback.status}")
    
    TASK_STORE[task_id]["final_logs"] = final_callback.execution_logs
    
    if final_callback.status == "success":
        await finalize_task(task_id, "resolved", "K8s ë¬¸ì œ í•´ê²° ì™„ë£Œ.")
    else:
        await finalize_task(task_id, "failed_resolution", "K8s ë¬¸ì œ í•´ê²° ì‹¤íŒ¨.")
        
async def process_buffered_events(pod_key: str, background_tasks: BackgroundTasks):
    """
    1ë¶„ íƒ€ì´ë¨¸ê°€ ëë‚œ í›„, ë²„í¼ëœ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬.
    """
    if pod_key in POD_BUFFERS:
        buffer = POD_BUFFERS.pop(pod_key)
        events = buffer["events"]
        if events:
            combined_payload = combine_events(events)
            task_id = _generate_task_id()
            logger.info(f"ğŸ“¦ [BUFFER PROCESS] Processing {len(events)} events for pod {pod_key} as task {task_id}")
            background_tasks.add_task(_start_workflow, task_id, combined_payload)
        else:
            logger.info(f"ğŸ“¦ [BUFFER PROCESS] No events for pod {pod_key}")

async def _auto_approve_if_pending(task_id: str):
    if task_id not in TASK_STORE:
        return

    if TASK_STORE[task_id]["status"] != "awaiting_approval":
        logger.info(f"â„¹ï¸ [AUTO APPROVE] Task {task_id} no longer awaiting approval. Skipping auto-approve.")
        return

    logger.warning(f"â° [AUTO APPROVE] Task {task_id} timed out (no response). Auto-approving.")
    TASK_STORE[task_id]["status"] = "auto_approved"
    TASK_STORE[task_id]["history"].append({
        "step": "auto_approved",
        "timestamp": datetime.utcnow().isoformat() + 'Z',
        "reason": "Timeout after 5 minutes - automatic approval"
    })

    # íƒ€ì´ë¨¸ ì·¨ì†Œ ë° ì œê±°
    if "approval_timer" in TASK_STORE[task_id]:
        TASK_STORE[task_id]["approval_timer"].cancel()
        del TASK_STORE[task_id]["approval_timer"]

    # ìë™ ì‹¤í–‰
    final_analyze_cmd = AnalyzeCommandResponse(**TASK_STORE[task_id]["final_commands"])
    await _execute_final_command(task_id, final_analyze_cmd)

    # === safe_detailsë¡œ ë³´ë‚´ê¸° ===
    safe_details = TASK_STORE[task_id].copy()
    safe_details.pop("approval_timer", None)

    timeout_req = {
        "task_id": task_id,
        "status": "auto_approved",
        "summary": "5ë¶„ ë™ì•ˆ ì‘ë‹µ ì—†ì–´ ìë™ ìŠ¹ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "details": safe_details
    }
    await _http_post(f"{NOTIFIER_URL}/notify/completion", timeout_req, task_id, "NOTIFIER_AUTO_APPROVE")

async def finalize_task(task_id: str, final_status: str, summary: str):
    """
    ëª¨ë“  ì›Œí¬í”Œë¡œìš° ì¢…ë£Œ ì‹œ í˜¸ì¶œí•˜ì—¬ ìƒíƒœ ì—…ë°ì´íŠ¸ + ì™„ë£Œ ì•Œë¦¼ ì „ì†¡
    """
    if task_id not in TASK_STORE:
        return

    TASK_STORE[task_id]["status"] = final_status
    TASK_STORE[task_id]["history"].append({
        "step": final_status,
        "timestamp": datetime.utcnow().isoformat() + 'Z'
    })

    # === ìˆ˜ì • í¬ì¸íŠ¸: TimerHandle ê°™ì€ ë¹„ì§ë ¬í™” ê°ì²´ ì œê±° ===
    safe_details = TASK_STORE[task_id].copy()
    safe_details.pop("approval_timer", None)  # íƒ€ì´ë¨¸ ê°ì²´ ì œê±°

    completion_req = {
        "task_id": task_id,
        "status": final_status,
        "summary": summary,
        "details": safe_details  # ì•ˆì „í•œ ë”•ì…”ë„ˆë¦¬ë§Œ ë³´ëƒ„
    }
    await _http_post(f"{NOTIFIER_URL}/notify/completion", completion_req, task_id, "NOTIFIER_COMPLETION")
    logger.info(f"ğŸ‰ [WORKFLOW COMPLETE] Task {task_id} finished with status: {final_status}")

# --- API ì—”ë“œí¬ì¸íŠ¸ ---

@app.post('/detect', response_model=DetectResponse)
async def detect_endpoint(req: DetectRequest, background_tasks: BackgroundTasks, authorization: Optional[str] = Header(None),):
    """Detector Agentë¡œë¶€í„° K8s ì´ìƒ íƒì§€ ì•Œë¦¼ ìˆ˜ì‹ """
    if BOSS_TOKEN:
        if not authorization or not authorization.startswith("Bearer "):
            raise HTTPException(status_code=401, detail="Missing Authorization header")
        token = authorization.split(" ", 1)[1]

        if not secrets.compare_digest(token, BOSS_TOKEN):
            raise HTTPException(status_code=403, detail="Invalid token")
    
    pod_key = f"{req.namespace}/{req.pod_name}"
    payload = req.dict()
    now = datetime.utcnow()
    logger.info(f"ğŸ“© [POST /detect] Received event from {pod_key}")
    
    
    # ë²„í¼ì— ì´ë²¤íŠ¸ ì¶”ê°€
    if pod_key not in POD_BUFFERS:
        POD_BUFFERS[pod_key] = {"events": [], "timer": None, "start_time": now}

    POD_BUFFERS[pod_key]["events"].append(payload)

    # ìµœëŒ€ 3ë¶„ ëŒ€ê¸°: start_timeë¶€í„° 3ë¶„ ì§€ë‚¬ìœ¼ë©´ ì¦‰ì‹œ ì²˜ë¦¬
    if (now - POD_BUFFERS[pod_key]["start_time"]) > timedelta(minutes=2):
        logger.info(f"â° [BUFFER MAX TIME] Max buffer time exceeded for {pod_key}. Processing immediately.")
        if POD_BUFFERS[pod_key]["timer"]:
            POD_BUFFERS[pod_key]["timer"].cancel()
        await process_buffered_events(pod_key, background_tasks)
        # ì¦‰ì‹œ task_id ë°˜í™˜ì„ ìœ„í•´ temp ì‚¬ìš©
        temp_task_id = _generate_task_id()
        return DetectResponse(status="processed_max_time", task_id=temp_task_id)

    # ê¸°ì¡´ íƒ€ì´ë¨¸ ì·¨ì†Œí•˜ê³  ìƒˆ 1ë¶„ íƒ€ì´ë¨¸ ì„¤ì • (ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ë¡œë¶€í„° 1ë¶„ ëŒ€ê¸°)
    if POD_BUFFERS[pod_key]["timer"]:
        POD_BUFFERS[pod_key]["timer"].cancel()

    loop = asyncio.get_running_loop()
    POD_BUFFERS[pod_key]["timer"] = loop.call_later(60, lambda: background_tasks.add_task(process_buffered_events, pod_key, background_tasks))
    
    # ì¦‰ì‹œ task_id ë°˜í™˜ (ë²„í¼ë§ ì¤‘ì´ë¯€ë¡œ ì‹¤ì œ task_idëŠ” ë‚˜ì¤‘ì— ìƒì„±ë˜ì§€ë§Œ, ì„ì‹œë¡œ ìƒì„±)
    temp_task_id = _generate_task_id()
    return DetectResponse(status="buffered", task_id=temp_task_id)


@app.post('/executor/callback')
async def executor_callback_endpoint(req: ExecutorCallback, background_tasks: BackgroundTasks):
    task_id = req.task_id
    
    if task_id not in TASK_STORE:
        raise HTTPException(status_code=404, detail="Task not found")

    current_status = TASK_STORE[task_id]["status"]
    
    if current_status in ("executing_read_commands", "executing_write_commands", "auto_approved"):
        if current_status == "executing_read_commands":
            background_tasks.add_task(_continue_workflow_after_read, task_id, req)
        elif current_status in ("executing_write_commands", "auto_approved"):
            background_tasks.add_task(_complete_workflow, task_id, req)
        return {"status": "accepted"}
    else:
        logger.warning(f"âš ï¸ [EXECUTOR CALLBACK] Unexpected callback for task {task_id} in status {current_status}")
        raise HTTPException(status_code=400, detail=f"Unexpected callback in status {current_status}")
        
@app.post('/slack/callback')
async def slack_callback_endpoint(req: SlackCallback, background_tasks: BackgroundTasks):
    # Slack Notifierë¡œë¶€í„° ìš´ì˜ì ìŠ¹ì¸/ê±°ë¶€ ê²°ê³¼ ìˆ˜ì‹ 
    task_id = req.task_id
    
    if task_id not in TASK_STORE:
        raise HTTPException(status_code=404, detail="Task not found")

    if TASK_STORE[task_id]["status"] != "awaiting_approval":
        logger.warning(f"âš ï¸ [SLACK CALLBACK] Received unexpected callback for task {task_id} in status {TASK_STORE[task_id]['status']}")
        raise HTTPException(status_code=400, detail=f"Unexpected callback in status {TASK_STORE[task_id]['status']}")

    TASK_STORE[task_id]["history"].append({"step": "approval_received", "timestamp": datetime.utcnow().isoformat() + 'Z', "approved": req.approved, "reason": req.reason})

    if req.approved:
        logger.info(f"âœ… [SLACK CALLBACK] Task {task_id} approved by operator.")
        final_analyze_cmd = AnalyzeCommandResponse(**TASK_STORE[task_id]["final_commands"])
        background_tasks.add_task(_execute_final_command, task_id, final_analyze_cmd)
    else:
        logger.warning(f"âŒ [SLACK CALLBACK] Task {task_id} rejected by operator. Reason: {req.reason}")
        TASK_STORE[task_id]["status"] = "rejected_by_operator"
        # ì™„ë£Œ ì•Œë¦¼ ì „ì†¡
        completion_req = {
            "task_id": task_id,
            "status": TASK_STORE[task_id]["status"],
            "summary": "K8s ë¬¸ì œ í•´ê²° ëª…ë ¹ ìš´ì˜ì ê±°ë¶€.",
            "details": TASK_STORE[task_id]
        }
        await _http_post(f"{NOTIFIER_URL}/notify/completion", completion_req, task_id, "NOTIFIER_REJECTION_COMPLETION")
        
    return {"status": "accepted"}


@app.get('/health')
async def health():
    #Health Check
    return {"status": "ok"}


@app.get('/tasks/{task_id}')
async def get_task(task_id: str):
    """íŠ¹ì • Taskì˜ í˜„ì¬ ìƒíƒœ ì¡°íšŒ"""
    task = TASK_STORE.get(task_id)
    if not task:
        raise HTTPException(status_code=404, detail='task not found')
    return task

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8032, log_level="info")